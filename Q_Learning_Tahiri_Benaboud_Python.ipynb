{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZJwwQiJjRpB"
      },
      "outputs": [],
      "source": [
        "#Importation des bibliothèques\n",
        "import numpy as np\n",
        "import math\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q matrix**"
      ],
      "metadata": {
        "id": "7zmEmtwLLPq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Définition de la forme de l'environnement (ses positions)\n",
        "environment_rows = 10\n",
        "environment_columns = 10\n",
        "#Création un tableau numpy 3D pour contenir la matrice Q actuelle pour chaque paire state/action : Q(s, a) \n",
        "#Le tableau contient 10 lignes et 10 colonnes (pour correspondre à l'environnement), ainsi qu'une troisième dimension \"action\".\n",
        "#La valeur de chaque paire Q(état, action) est initialisée à 0.\n",
        "q_values = np.zeros((environment_rows, environment_columns, 4))\n",
        "print(q_values)"
      ],
      "metadata": {
        "id": "UhK5Z2HdkMSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "509aca07-2fc8-48b7-8314-b2fd8f83e6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code des actions: 0 = Haut, 1 = Droit, 2 = Bas, 3 = Gauche\n",
        "actions = ['H', 'D', 'B', 'G']"
      ],
      "metadata": {
        "id": "DX5nvgF6kUCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reward matrix**"
      ],
      "metadata": {
        "id": "IPtzzPzDLKuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Créeation d'un tableau numpy 2D pour contenir les récompenses pour chaque state \n",
        "# Le tableau contient 10 lignes et 10 colonnes\n",
        "rewards = np.full((environment_rows, environment_columns), 1.)\n",
        "\n",
        "# La récompense du Goal est fixée à 10 pour encourager le robot à l'atteindre\n",
        "rewards[9, 9] = 10.\n",
        "\n",
        "# Calcul des récompenses pour tous les autres états en fonction de la distance au Goal.\n",
        "for x in range(environment_rows):\n",
        "    for y in range(environment_columns):\n",
        "        # Sauter le state Goal (il a déjà été défini).\n",
        "        if (x, y) == (9, 9):\n",
        "            continue\n",
        "        \n",
        "        # Calcul de la distance entre l'état actuel et le goal.\n",
        "        distance = math.sqrt((x - 9)**2 + (y - 9)**2)\n",
        "        \n",
        "        # On met la récompense pour l'état actuel à l'inverse de la distance.\n",
        "        rewards[x, y] = 1.0 / distance\n",
        "\n",
        "#Définir une récompense négative pour les obstacles à -10 pour punir le robot.\n",
        "rewards[0,5] = -10\n",
        "rewards[0,6] = -10\n",
        "rewards[3,3] = -10\n",
        "rewards[3,4] = -10\n",
        "rewards[6,5] = -10\n",
        "rewards[6,6] = -10\n",
        "# Affichage de la matrice de récompenses\n",
        "rounded_rewards = np.round(rewards, 3)\n",
        "print(tabulate(rounded_rewards, tablefmt='grid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLNXukiTvD2X",
        "outputId": "87a0fdd5-6b08-4bf2-d558-0f1d9356adf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-------+---------+---------+---------+---------+-------+-------+--------+\n",
            "| 0.079 | 0.083 | 0.088 |   0.092 |   0.097 | -10     | -10     | 0.108 | 0.11  |  0.111 |\n",
            "+-------+-------+-------+---------+---------+---------+---------+-------+-------+--------+\n",
            "| 0.083 | 0.088 | 0.094 |   0.1   |   0.106 |   0.112 |   0.117 | 0.121 | 0.124 |  0.125 |\n",
            "+-------+-------+-------+---------+---------+---------+---------+-------+-------+--------+\n",
            "| 0.088 | 0.094 | 0.101 |   0.108 |   0.116 |   0.124 |   0.131 | 0.137 | 0.141 |  0.143 |\n",
            "+-------+-------+-------+---------+---------+---------+---------+-------+-------+--------+\n",
            "| 0.092 | 0.1   | 0.108 | -10     | -10     |   0.139 |   0.149 | 0.158 | 0.164 |  0.167 |\n",
            "+-------+-------+-------+---------+---------+---------+---------+-------+-------+--------+\n",
            "| 0.097 | 0.106 | 0.116 |   0.128 |   0.141 |   0.156 |   0.171 | 0.186 | 0.196 |  0.2   |\n",
            "+-------+-------+-------+---------+---------+---------+---------+-------+-------+--------+\n",
            "| 0.102 | 0.112 | 0.124 |   0.139 |   0.156 |   0.177 |   0.2   | 0.224 | 0.243 |  0.25  |\n",
            "+-------+-------+-------+---------+---------+---------+---------+-------+-------+--------+\n",
            "| 0.105 | 0.117 | 0.131 |   0.149 |   0.171 | -10     | -10     | 0.277 | 0.316 |  0.333 |\n",
            "+-------+-------+-------+---------+---------+---------+---------+-------+-------+--------+\n",
            "| 0.108 | 0.121 | 0.137 |   0.158 |   0.186 |   0.224 |   0.277 | 0.354 | 0.447 |  0.5   |\n",
            "+-------+-------+-------+---------+---------+---------+---------+-------+-------+--------+\n",
            "| 0.11  | 0.124 | 0.141 |   0.164 |   0.196 |   0.243 |   0.316 | 0.447 | 0.707 |  1     |\n",
            "+-------+-------+-------+---------+---------+---------+---------+-------+-------+--------+\n",
            "| 0.111 | 0.125 | 0.143 |   0.167 |   0.2   |   0.25  |   0.333 | 0.5   | 1     | 10     |\n",
            "+-------+-------+-------+---------+---------+---------+---------+-------+-------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fonctions d'aide**"
      ],
      "metadata": {
        "id": "bdcR60ebgbJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction pour vérifier si l'état actuel est un état terminal aka (goal)\n",
        "def is_terminal_state(actual_x, actual_y):\n",
        "  # Si la récompense pour cet état est différente de 10, alors il ne s'agit pas d'un état terminal. \n",
        "  if rewards[actual_x, actual_y] != 10:\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "# Fonction pour choisir un état de départ aléatoire pour boucler dans l'environnement\n",
        "def get_random_starting_location():\n",
        "  actual_x = np.random.randint(environment_rows)\n",
        "  actual_y = np.random.randint(environment_columns)\n",
        "  # Continuer à choisir des index de lignes et de colonnes aléatoires même lorsque le goal est atteint\n",
        "  while is_terminal_state(actual_x, actual_y):\n",
        "    actual_x = np.random.randint(environment_rows)\n",
        "    actual_y = np.random.randint(environment_columns)\n",
        "  return actual_x, actual_y\n",
        "  \n",
        "#un algorithme avide d'epsilon qui choisira l'action suivante (c'est-à-dire l'endroit où se déplacer ensuite)\n",
        "def choose_next_action(actual_x, actual_y, epsilon):\n",
        "  # Si une valeur choisie au hasard entre 0 et 1 est inférieure à epsilon\n",
        "  # on choisit alors la valeur la plus prometteuse de la matrice Q pour cet état.\n",
        "  if np.random.random() < epsilon:\n",
        "    return np.argmax(q_values[actual_x, actual_y])\n",
        "  # Sinon on choisit une action aléatoire\n",
        "  else: \n",
        "    return np.random.randint(4)\n",
        "\n",
        "# Fonction qui obtiendra la prochaine position \"état suivant\" en fonction de l'action choisie.\n",
        "def get_next_state(actual_x, actual_y, action_index):\n",
        "  next_x = actual_x\n",
        "  next_y = actual_y\n",
        "  if actions[action_index] == 'H' and actual_x > 0:\n",
        "    next_x -= 1\n",
        "  elif actions[action_index] == 'D' and actual_y < environment_columns - 1:\n",
        "    next_y += 1\n",
        "  elif actions[action_index] == 'B' and actual_x < environment_rows - 1:\n",
        "    next_x += 1\n",
        "  elif actions[action_index] == 'G' and actual_y > 0:\n",
        "    next_y -= 1\n",
        "  return next_x, next_y\n",
        "\n",
        "# Fonction qui trouvera le chemin optimale entre n'importe quel état initial et l'état finale\n",
        "def shortest_path(start_x, start_y):\n",
        "  # Retourner immédiatement si l'état initiale est l'état finale\n",
        "  if is_terminal_state(start_x, start_y):\n",
        "    return []\n",
        "  else:\n",
        "    actual_x, actual_y = start_x, start_y\n",
        "    shortest_path = []\n",
        "    shortest_path.append([actual_x, actual_y])\n",
        "    # Se déplacer sans arrêt le long du chemin jusqu'à ce que nous atteignions le goal\n",
        "    while not is_terminal_state(actual_x, actual_y):\n",
        "      # On obtient l'action optimale à prendre\n",
        "      action_index = choose_next_action(actual_x, actual_y,1)\n",
        "      # Se déplacer vers l'état suivant suivant sur le chemin, et ajouter le nouvel état à la liste\n",
        "      next_x, next_y = get_next_state(actual_x, actual_y, action_index)\n",
        "      if (next_x,next_y != actual_x,actual_y):\n",
        "        actual_x,actual_y = next_x,next_y\n",
        "        shortest_path.append([actual_x, actual_y])\n",
        "      else:\n",
        "        continue\n",
        "    return shortest_path"
      ],
      "metadata": {
        "id": "Fp4nWa0DknOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning episodes**"
      ],
      "metadata": {
        "id": "dq4JaN3JgVAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Le pourcentage de temps où nous devrions prendre l'action optimale (au lieu d'une action aléatoire)\n",
        "epsilon = 0.9 \n",
        "# Paramètre d'apprentissage gamma\n",
        "gamma = 0.7\n",
        "\n",
        "# Exécuter 1000 épisodes d'entrainement\n",
        "for episode in range(1000):\n",
        "  # On choisit un état initiale aléatoire\n",
        "  x, y = get_random_starting_location()\n",
        "  # On explore notre environment jusqu'à ce qu'on arrive à l'état finale\n",
        "  while not is_terminal_state(x, y):\n",
        "    # On choisit une action pour se déplacer\n",
        "    action_index = choose_next_action(x, y, epsilon)\n",
        "    # On se déplace vers le prochain état à l'aide de l'action choisie\n",
        "    past_x, past_y = x, y # on stocke l'ancien état\n",
        "    x, y = get_next_state(x, y, action_index)\n",
        "    # On reçoit la récompense du passage à l'état suivant\n",
        "    # On calcule les nouvelles valeurs de la matrice Q pour l'ancien état\n",
        "    reward = rewards[x, y]\n",
        "    new_q_value = reward + (gamma * np.max(q_values[x, y]))\n",
        "    # On met à jour la valeur Q pour l'ancien état et l'action performée\n",
        "    q_values[past_x, past_y, action_index] = new_q_value\n",
        "\n",
        "# Après l'exécution de 1000 épisodes, on affiche un message\n",
        "print('Exploration terminée !')\n",
        "# Affichage de la matrice Q\n",
        "print(q_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aWW0CUGlTSM",
        "outputId": "49576f51-0fc8-4100-aed3-7f917eb79719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exploration terminée !\n",
            "[[[  0.33291555   0.36335447   0.29721072   0.        ]\n",
            "  [  0.32761027   0.39862343   0.40044142   0.30707465]\n",
            "  [  0.30106303   0.44416805   0.30483558   0.28328873]\n",
            "  [  0.20246557   0.           0.5024543    0.        ]\n",
            "  [  0.32375945  -9.53923389   0.57246928   0.        ]\n",
            "  [ -9.54332907  -9.74691448   0.66194075   0.        ]\n",
            "  [-10.           0.65488979   0.          -9.66555356]\n",
            "  [  0.65488979   0.78060651   0.57969067  -9.54157715]\n",
            "  [  0.78060651   0.95739284   0.5298182    0.65488979]\n",
            "  [  0.37035844   0.95739284   1.2089739    0.78060651]]\n",
            "\n",
            " [[  0.30595034   0.40044142   0.           0.3264389 ]\n",
            "  [  0.32761027   0.4457901    0.           0.36335447]\n",
            "  [  0.39862343   0.5024543    0.32702553   0.34937827]\n",
            "  [  0.43965268   0.57246928   0.57493472   0.4457901 ]\n",
            "  [  0.49785708   0.           0.66638499   0.        ]\n",
            "  [ -9.71909882   0.52282461   0.7859105    0.36739584]\n",
            "  [ -9.54157715   0.57969067   0.49728366   0.47778063]\n",
            "  [  0.65488979   0.5298182    0.54314403   0.52282461]\n",
            "  [  0.40369343   1.2089739    0.           0.57969067]\n",
            "  [  0.95739284   1.2089739    1.54853414   0.97031646]]\n",
            "\n",
            " [[  0.36335447   0.2987188    0.33142928   0.29886436]\n",
            "  [  0.           0.           0.49221417   0.3197063 ]\n",
            "  [  0.4457901    0.           0.36069748   0.40944671]\n",
            "  [  0.49600378   0.66638499  -9.70517128   0.41306832]\n",
            "  [  0.57246928   0.7859105   -9.53353051   0.57493472]\n",
            "  [  0.66194075   0.93061012   0.94553681   0.66638499]\n",
            "  [  0.52282461   0.78878765   1.14186241   0.78061985]\n",
            "  [  0.57969067   0.5122941    0.5383147    0.93061012]\n",
            "  [  0.97031646   0.           0.85253712   0.78878765]\n",
            "  [  1.2089739    1.54853414   2.00811      0.82064288]]\n",
            "\n",
            " [[  0.29886436   0.49221417   0.34139892   0.        ]\n",
            "  [  0.32168391   0.39540053   0.56030596   0.43699995]\n",
            "  [  0.41306832   0.           0.           0.        ]\n",
            "  [  0.57493472   0.           0.           0.        ]\n",
            "  [  0.66638499   0.           0.          -9.75504773]\n",
            "  [  0.7859105    1.14186241   1.15265965  -9.53353051]\n",
            "  [  0.91867083   0.5383147    1.41827316   0.        ]\n",
            "  [  0.78043014   0.84417961   1.17848655   1.14186241]\n",
            "  [  0.           0.           0.           0.98305447]\n",
            "  [  1.54853414   2.00811      2.63063333   0.85253712]]\n",
            "\n",
            " [[  0.43699995   0.           0.55584079   0.48621714]\n",
            "  [  0.45053518   0.36462159   0.64900882   0.48621714]\n",
            "  [  0.39540053   0.           0.           0.56030596]\n",
            "  [ -9.70517128   0.94828311   0.           0.50846181]\n",
            "  [ -9.69397088   1.15265965   0.81997194   0.79183506]\n",
            "  [  0.94553681   1.41827316   1.42355127   0.94828311]\n",
            "  [  1.14186241   1.17848655   1.78110654   1.15265965]\n",
            "  [  0.98305447   1.00911743   0.           1.41827316]\n",
            "  [  0.54121928   2.63063333   0.           1.17848655]\n",
            "  [  2.00811      2.63063333   3.47233333   2.03755947]]\n",
            "\n",
            " [[  0.48621714   0.64900882   0.35499092   0.55174561]\n",
            "  [  0.37856895   0.76743632   0.5118059    0.55584079]\n",
            "  [  0.378151     0.69295959   0.91914512   0.64900882]\n",
            "  [  0.79183506   0.           0.           0.        ]\n",
            "  [  0.94828311   0.           0.           0.67749499]\n",
            "  [  1.15265965   1.78110654  -8.41889346   0.81997194]\n",
            "  [  1.41827316   2.25872363  -7.96488317   1.42355127]\n",
            "  [  1.17848655   2.84636735   2.90730976   1.78110654]\n",
            "  [  0.57496963   3.47233333   3.71975961   2.25872363]\n",
            "  [  2.63063333   3.47233333   4.60333333   2.77532972]]\n",
            "\n",
            " [[  0.34655964   0.76044273   0.35441998   0.35136416]\n",
            "  [  0.56394965   0.91914512   0.41765151   0.        ]\n",
            "  [  0.76743632   1.12548384   1.06759165   0.76044273]\n",
            "  [  0.68710934   0.73962869   1.3948752    0.91914512]\n",
            "  [  0.81161444   0.           0.           1.12548384]\n",
            "  [  1.39918537  -8.01460951   2.25872363   0.95933727]\n",
            "  [  1.70615276   0.           2.90730976  -8.41889346]\n",
            "  [  2.25872363   3.71975961   3.75708523  -7.96488317]\n",
            "  [  2.71952839   4.60333333   4.86218834   2.75434287]\n",
            "  [  3.47233333   4.60333333   6.1          3.71975961]]\n",
            "\n",
            " [[  0.63771917   0.86858197   0.           0.        ]\n",
            "  [  0.63892963   1.06759165   0.58740048   0.71647261]\n",
            "  [  0.91914512   0.           1.32890155   0.66195106]\n",
            "  [  1.1084277    1.76680188   1.69640028   1.06759165]\n",
            "  [  0.95933727   2.25872363   2.18857328   1.3948752 ]\n",
            "  [ -8.41889346   2.90730976   1.85366841   1.76680188]\n",
            "  [ -7.96488317   3.75708523   3.71975961   2.25872363]\n",
            "  [  2.90730976   4.86218834   4.86218834   2.90730976]\n",
            "  [  3.71975961   6.1          6.30710678   3.75708523]\n",
            "  [  4.60333333   6.1          8.           4.86218834]]\n",
            "\n",
            " [[  0.71647261   0.           0.           0.        ]\n",
            "  [  0.86858197   0.           0.41666206   0.        ]\n",
            "  [  0.46344218   1.69640028   1.07308823   0.73204211]\n",
            "  [  1.3948752    2.18857328   0.91782843   0.        ]\n",
            "  [  1.76680188   2.84636735   0.70908306   1.69640028]\n",
            "  [  1.53573263   3.71975961   2.24245714   2.18857328]\n",
            "  [  2.90730976   4.86218834   2.93716506   2.84636735]\n",
            "  [  3.75708523   6.30710678   3.90353184   3.71975961]\n",
            "  [  4.86218834   8.           8.           4.86218834]\n",
            "  [  6.1          8.          10.           6.30710678]]\n",
            "\n",
            " [[  0.61196235   0.           0.           0.46861036]\n",
            "  [  0.73204211   0.           0.4166664    0.39918637]\n",
            "  [  1.32890155   0.28333333   0.79249228   0.        ]\n",
            "  [  0.49408514   0.2          0.55555505   1.07308823]\n",
            "  [  0.           0.           0.           0.91782843]\n",
            "  [  2.84636735   2.93716506   1.60583106   0.        ]\n",
            "  [  3.71975961   0.           0.           0.        ]\n",
            "  [  4.86218834   0.           0.           0.        ]\n",
            "  [  2.75405124  10.           8.           3.90353184]\n",
            "  [  0.           0.           0.           0.        ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chemin optimale**"
      ],
      "metadata": {
        "id": "E8gEcYKygj0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher quelques chemins optimales\n",
        "print(shortest_path(8, 9))\n",
        "print(shortest_path(0, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHozoHWmlZiu",
        "outputId": "818ccb2b-d0e3-4542-d9c0-cd507443d4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8, 9], [9, 9]]\n",
            "[[0, 0], [0, 1], [1, 1], [1, 2], [1, 3], [2, 3], [2, 4], [2, 5], [3, 5], [4, 5], [5, 5], [5, 6], [5, 7], [6, 7], [7, 7], [7, 8], [8, 8], [8, 9], [9, 9]]\n"
          ]
        }
      ]
    }
  ]
}